{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New features (updated 6/13/2019):\n",
    "    1. implementation for integrated plot\n",
    "    2. workflow tool can automatically create folders for plots and data info now\n",
    "    3. more well-structured output files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1\n",
    "- import workflow.py and need to make sure that integration_helpers.py is under the same dir as workflow.py<br/>\n",
    "- change '../' to your dir of workflow.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'deepchem'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-eba756b7d67f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mworkflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mwf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\projects\\moleprop\\util\\workflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mintegration_helpers\u001b[0m                               \u001b[1;31m# for removing duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mundo_transforms\u001b[0m  \u001b[1;31m# for getting real predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswitch_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'agg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'deepchem'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')     \n",
    "import workflow as wf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2\n",
    "- Loading raw data(dataset with duplicates) from the path of \"data_dir + file_name\" <br/>\n",
    "- Change data_dir and file_name to the path and file you want to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"About to load\")\n",
    "loader = wf.Loader\n",
    "data = loader.load(file_name = 'integrated_dataset.csv',data_dir = '/srv/home/xsun256/Moleprop/summer19')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3\n",
    "- Data cleaning (removing duplictaes) and splitting\n",
    "- Returns indices of training sets and test sets, and new dataset after removing duplicates\n",
    "- params:\n",
    "  - data: DataFrame\n",
    "  - n_splits (for k_fold splitter): n of n-fold cv\n",
    "  - test_group (for LOG splitter): name of the dataset you want to leave out as test group\n",
    "- Other params you can set:\n",
    "  - k_fold splitter:\n",
    "    - shuffle( = True in defualt): True or False\n",
    "  - LOG splitter: \n",
    "    - frac( = 1 in default): \n",
    "        - training set: all other datasets + (1-frac) * left-out dataset\n",
    "        - test set: frac* left-out dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"About to split\")\n",
    "splitter = wf.Splitter\n",
    "indices,dataset = splitter.k_fold(data, n_splits = 3)\n",
    "# indices,dataset = splitter.LOG(data,'left-out group name')  # LOG splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4\n",
    "- conduct CV or LOG_validation\n",
    "- Param:\n",
    "    - dataset: DataFrame\n",
    "    - indices: indices returned from splitter\n",
    "    - model name: accept \"GC\",\"GraphConv\",\"graphconv\", and \"MPNN\"\n",
    "    - model_args (= None in default): \n",
    "        - GC args:\n",
    "            - nb_epoch, \n",
    "            - batch_size, \n",
    "            - n_tasks, \n",
    "            - graph_conv_layers, \n",
    "            - dense_layer_size, \n",
    "            - dropout, \n",
    "            - mode\n",
    "        - MPNN args:\n",
    "            - 'n_tasks':1,\n",
    "            - 'n_atom_feat':75,\n",
    "            - 'n_pair_feat':14,      # NEED to be 14 for WaveFeaturizer\n",
    "            - 'T':1,\n",
    "            - 'M':1,\n",
    "            - 'batch_size':32,\n",
    "            - 'nb_epoch': 50,\n",
    "            - 'learning_rate':0.0001,\n",
    "            - 'use_queue':False,\n",
    "            - 'mode':\"regression\"\n",
    "     - metrics: accept \"AAD\", \"RMSE\", \"MAE\", \"R2\"\n",
    "- Return:\n",
    "    - scores: a dictionart of scores (based on the merics you set):\n",
    "        - avg_AAD and AAD_list (list of AAD score from every iteration)\n",
    "        - avg_R2 and R2_list\n",
    "        - avg_RMSE and RMSE_list\n",
    "        - avg_MAE and MAE_list\n",
    "    - predictions: list of predictions from every iteration\n",
    "    - test_Dataset: list of test datasets from every iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "GC_args_example = {'nb_epoch': 80,\n",
    "        'batch_size': 50,\n",
    "        'n_tasks': 1,\n",
    "        'graph_conv_layers':[64,64],\n",
    "        'dense_layer_size': 256,\n",
    "        'dropout': 0.0,           \n",
    "        'mode': 'regression'}\n",
    "'''\n",
    "print(\"About to simulate\")\n",
    "# Cross Validation\n",
    "scores,predictions,test_datasets = wf.Run.cv(dataset,indices, \n",
    "                                             'GC',\n",
    "                                             model_args = None,\n",
    "                                             n_splits = 3, \n",
    "                                             metrics = ['AAD', 'RMSE', 'MAE', 'R2'])\n",
    "# LOG validation\n",
    "'''\n",
    "scores,predictions,test_datasets = wf.Run.cv(dataset,indices, \n",
    "                                             'GC',\n",
    "                                             model_args = None,\n",
    "                                             metrics = ['AAD', 'RMSE', 'MAE', 'R2'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP5\n",
    "- Print out result and save parity plots and hitogram plots\n",
    "- Params:\n",
    "    - plot_name: name of plot without add '.png'\n",
    "    - text: **dictionary** of scores that you want to add to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make plots for every fold\n",
    "for key in scores:\n",
    "    print(key+\" = \"+str(scores[key]))\n",
    "\n",
    "print(\"About to make parity plots\")\n",
    "for i in range(len(predictions)):\n",
    "    p_name = \"parity_\"+str(i)\n",
    "    std = test_datasets[i]['flashpoint'].std()\n",
    "    txt = {\n",
    "           \"RMSE\":scores['RMSE_list'][i], \n",
    "           \"R2\":scores['R2_list'][i], \n",
    "           \"MAE\":scores['MAE_list'][i], \n",
    "           \"AAD\":scores['AAD_list'][i],\n",
    "           \"RMSE/std\":scores['RMSE_list'][i]/std}\n",
    "    wf.Plotter.parity_plot(predictions[i],test_datasets[i], plot_name = p_name, text = txt)\n",
    "\n",
    "print(\"About to make residual plot\")\n",
    "for i in range(len(predictions)):\n",
    "    r_name = \"residual_\"+str(i)\n",
    "    std = test_datasets[i]['flashpoint'].std()\n",
    "    txt = {\n",
    "           \"RMSE\":scores['RMSE_list'][i],\n",
    "           \"R2\":scores['R2_list'][i],\n",
    "           \"MAE\":scores['MAE_list'][i],\n",
    "           \"AAD\":scores['AAD_list'][i],\n",
    "           \"RMSE/std\":scores['RMSE_list'][i]/std}\n",
    "    wf.Plotter.residual_histogram(predictions[i],test_datasets[i], plot_name = r_name, text = txt)\n",
    "\n",
    "# For making integrated plots \n",
    "print(\"About to plot full data\")\n",
    "P = predictions[0] + predictions[1]+ predictions[2]\n",
    "D = pd.concat(test_datasets)\n",
    "txt = {'RMSE/STD': scores['RMSE']/D['flashpoint'].std(),\n",
    "       'RMSE': scores['RMSE'],\n",
    "       'MAE': scores['MAE'],\n",
    "       'R2': scores['R2'],\n",
    "       'AAD': scores['AAD']}\n",
    "wf.Plotter.parity_plot(P,D,plot_name = \"Full_parity\", text = txt)\n",
    "wf.Plotter.residual_histogram(P,D,plot_name = \"Full_residual\", text = txt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
